{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported libraries and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'd:\\\\FEUP\\\\4 Ano\\\\AC\\\\ac-feup\\\\jupyters\\\\utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### imported Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sqlite3\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "### Sklearn imported libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Pipeline for Oversampling\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Imported Scripts\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERSMAPLE = True\n",
    "DEBUG = True\n",
    "WRITE = True\n",
    "DUMMIES = True\n",
    "CATEGORY_ENCONDING = False\n",
    "MIN_MAX_SCALER = False\n",
    "SPLIT_RATIO = 0.8\n",
    "N_COLUMNS = 15\n",
    "N_SPLITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Dataset Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummy(df,columns):\n",
    "    copy= df.copy()\n",
    "\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(copy[column])\n",
    "        copy = copy.drop(column,axis=1)\n",
    "        copy = copy.join(dummies)\n",
    "    \n",
    "    return copy\n",
    "\n",
    "def convert_dates(df):\n",
    "    copy = df.copy()\n",
    "    columns = [\"loan_date\",\"account_creation\",\"birth_number\"]\n",
    "\n",
    "    for column in columns:\n",
    "        copy[column] = copy[column].apply(lambda x: datetime.datetime.strptime(x, '%d-%m-%Y').strftime('%Y')).astype(int)\n",
    "\n",
    "    copy[\"age_on_loan\"] = copy[\"loan_date\"] - copy[\"birth_number\"]\n",
    "    copy = copy.drop(columns = [\"loan_date\",\"account_creation\",\"birth_number\"])\n",
    "\n",
    "    copy['card_issued'] = pd.to_numeric(copy[\"card_issued\"].astype(str), errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "    return copy\n",
    "\n",
    "def get_df(test=False):\n",
    "    con = sqlite3.connect(\"../database/banking_data\")\n",
    "    if test:\n",
    "        df = pd.read_sql_query(\"SELECT * FROM loan_united_test\", con)\n",
    "    else:\n",
    "        df = pd.read_sql_query(\"SELECT * FROM loan_united_train\", con)\n",
    "\n",
    "    df = convert_dates(df)\n",
    "    con.close()\n",
    "\n",
    "    if DUMMIES:\n",
    "        columns = [\"account_frequency\",\"gender\",\"card_type\"]\n",
    "        df = add_dummy(df, columns)\n",
    "\n",
    "    if CATEGORY_ENCONDING:\n",
    "        df = utils.normalize_category(df)\n",
    "\n",
    "    \n",
    "    if MIN_MAX_SCALER:\n",
    "        scaler = MinMaxScaler()\n",
    "        copy = df.copy()\n",
    "        y = copy[\"status\"]\n",
    "        X = copy.drop(columns=[\"status\"])\n",
    "        transf = scaler.fit_transform(X)\n",
    "        copy = pd.DataFrame(transf,index=X.index,columns=X.columns)\n",
    "        copy[\"status\"] = y\n",
    "        df = copy\n",
    "        \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data\n",
    "def split_dataset(df):\n",
    "\n",
    "    ### Seperate the precition columns from output\n",
    "    \n",
    "    X = df.drop(columns=['status'])\n",
    "    y = df['status']\n",
    "\n",
    "    select = SelectKBest(f_classif, k= N_COLUMNS)\n",
    "    X_new = select.fit_transform(X, y)\n",
    "\n",
    "    split_filter = select.get_support()\n",
    "    features = X.columns\n",
    "\n",
    "    ### Apply splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new,y,train_size=SPLIT_RATIO,test_size=1-SPLIT_RATIO)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test, features[split_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest():\n",
    "    return RandomForestClassifier(bootstrap = False,\n",
    "                                    max_depth =110,\n",
    "                                    max_features = 2,\n",
    "                                    min_samples_leaf = 3,\n",
    "                                    min_samples_split = 8,\n",
    "                                    n_estimators = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logistic_regression():\n",
    "    return LogisticRegression(random_state=10,\n",
    "                                solver='lbfgs',\n",
    "                                max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree():\n",
    "    return DecisionTreeClassifier(criterion='entropy',\n",
    "                                    max_depth=5,\n",
    "                                    max_features=\"sqrt\",\n",
    "                                    min_impurity_split=\"0.1\",\n",
    "                                    min_samples_leaf=4,\n",
    "                                    min_samples_split=8,\n",
    "                                    splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn():\n",
    "    return KNeighborsClassifier(algorithm=\"ball_tree\",\n",
    "                                    leaf_size=\"50\",\n",
    "                                    metric=\"chebyshev\",\n",
    "                                    n_neighbors=10,\n",
    "                                    p=10,\n",
    "                                    weights=\"uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use *Grid Search Cross Validation* to find the best grid for an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rf():\n",
    "    return  RandomForestClassifier()\n",
    "def create_knn():\n",
    "    return  KNeighborsClassifier()\n",
    "def create_dt():\n",
    "    return  DecisionTreeClassifier()\n",
    "def create_lr():\n",
    "    return  LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uses a grid search to generate random parameters to find the best grid model\n",
    "def getBestSearch(algorithm,grid):\n",
    "    train = get_df()\n",
    "\n",
    "    X = train.drop(columns=['status'])\n",
    "    y = train['status']\n",
    "\n",
    "    if algorithm == \"RF\":\n",
    "        alg = build_pipeline(create_rf())\n",
    "    elif algorithm == \"KNN\":\n",
    "        alg = build_pipeline(create_knn())\n",
    "    elif algorithm == \"DT\":\n",
    "        alg = build_pipeline(create_dt())\n",
    "    elif algorithm == \"LR\":\n",
    "        alg = build_pipeline(create_lr())\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = alg,\n",
    "                               param_grid = grid, \n",
    "                               scoring=metrics.make_scorer(utils.get_auc, greater_is_better=True),\n",
    "                               cv=StratifiedKFold(2,random_state=30,shuffle=True),\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 2)\n",
    "\n",
    "    model = grid_search.fit(X,y)\n",
    "\n",
    "    if DEBUG:\n",
    "        print('Best Score: ', model.best_score_)\n",
    "        print('Best Params: ', model.best_params_)\n",
    "    \n",
    "    return model.best_score_, model.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Pipeline to apply a sampling and a classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Add undersample before final delivery\n",
    "def build_pipeline(algorithm):\n",
    "\n",
    "    if(OVERSMAPLE):\n",
    "        return Pipeline([\n",
    "            ('sampling',SMOTE()),\n",
    "            ('classification',algorithm)\n",
    "        ])\n",
    "    else:\n",
    "        return  Pipeline([\n",
    "            ('classification',algorithm)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Stratified Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_CV(algorithm):\n",
    "    train = get_df()\n",
    "    # train = utils.normalization(train,'status')\n",
    "\n",
    "    X = train.drop(columns=['status'])\n",
    "    y = train['status']\n",
    "\n",
    "    select = SelectKBest(f_classif, k=N_COLUMNS)\n",
    "    X_new = select.fit_transform(X, y)\n",
    "\n",
    "    split_filter = select.get_support()\n",
    "    features = X.columns[split_filter]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=True, shuffle=True)\n",
    "\n",
    "    model_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_new, y):\n",
    "\n",
    "        X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        ### Train the model\n",
    "        pipe = build_pipeline(algorithm())\n",
    "        model = pipe.fit(X_train, y_train)\n",
    "\n",
    "        ### Predict the outcome with the test data\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        y_final = y_pred.transpose()[0]\n",
    "        \n",
    "        auc = utils.get_auc(y_test, y_final)\n",
    "        auc_list.append(auc)\n",
    "        model_list.append(model)\n",
    "        print(f\"AUC={auc}\")\n",
    "        \n",
    "    ### Get the best model\n",
    "\n",
    "    best_score = max(auc_list)\n",
    "    best_model = model_list[auc_list.index(best_score)]\n",
    "    \n",
    "    \n",
    "    ### Use the best model to get a prediction\n",
    "    test = get_df(test=True)\n",
    "    \n",
    "    X2 = test.drop(columns=['status'])\n",
    "    X2 = X2[features]\n",
    "\n",
    "    y_predicted = best_model.predict_proba(X2)\n",
    "    y_final = y_predicted.transpose()[0]\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    final_df['Id'] = test[\"loan_id\"]\n",
    "    final_df['Predicted'] = y_final\n",
    "\n",
    "    avg = sum(auc_list)/len(auc_list)\n",
    "    print(f\"Average AUC = {avg}\")\n",
    "    print(f\"Best AUC = {best_score}\")\n",
    "    \n",
    "    \n",
    "    if DEBUG:\n",
    "        print(f\"Predictions:\\n {final_df}\")\n",
    "    \n",
    "    if WRITE:\n",
    "        final_df.to_csv('../csvs/results/final.csv', index=False)\n",
    "        print(\"Sucessfully stored the predictions in a file named 'final.csv'\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_algorithm(algorithm):\n",
    "    ### Getting the dataset\n",
    "    train = get_df(test=False)\n",
    "    ### Getting a Model from training\n",
    "    \n",
    "    X_train,X_test,y_train,y_test, features = split_dataset(train)\n",
    "\n",
    "    \n",
    "    pipe = build_pipeline(algorithm())\n",
    "    model = pipe.fit(X_train,y_train)\n",
    "\n",
    "    y_predicted = model.predict_proba(X_test)\n",
    "\n",
    "    y_final = y_predicted.transpose()[0]\n",
    "\n",
    "    if DEBUG:\n",
    "        score = model.score(X_test,y_test)\n",
    "        auc = utils.get_auc(y_test,y_final,label=-1)\n",
    "        # plot_auc(y_test,y_final)\n",
    "        # conf_matrix(model,y_test,y_final)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Auc: {auc}\")\n",
    "    \n",
    "    return model, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(model,features):\n",
    "\n",
    "    test = get_df(test=True)\n",
    "\n",
    "    X = test.drop(columns=['status'])\n",
    "    X = X[features]\n",
    "\n",
    "    print(X.columns)\n",
    "\n",
    "    y_predicted = model.predict_proba(X)\n",
    "    y_final = y_predicted.transpose()[0]\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    final_df['Id'] = test[\"loan_id\"]\n",
    "    final_df['Predicted'] = y_final\n",
    "\n",
    "    if DEBUG:\n",
    "        print(f\"Predictions:\\n {final_df}\")\n",
    "        \n",
    "    \n",
    "    if WRITE:\n",
    "        final_df.to_csv('../csvs/results/testing_model.csv', index=False)\n",
    "        print(\"Sucessfully stored the predictions in a file named 'testing_model.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(algorithm):\n",
    "    \n",
    "    if(DEBUG):\n",
    "        print(\"Running the provided algorithm\")\n",
    "    \n",
    "    model, features = training_algorithm(algorithm)\n",
    "    testing_model(model,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leave the one you want to run uncommented\n",
    "algorithm = get_random_forest\n",
    "# algorithm = get_logistic_regression\n",
    "# algorithm = get_decision_tree\n",
    "# algorithm = get_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the provided algorithm\n",
      "Score: 0.9545454545454546\n",
      "Auc: 0.8994708994708995\n",
      "Index(['index', 'loan_id', 'loan_amount', 'payments',\n",
      "       'client_district no. of municipalities with inhabitants < 499',\n",
      "       'client_district no. of cities', 'client_district unemploymant_growth',\n",
      "       'card_issued', 'no. movements', 'min no. trans', 'min balance',\n",
      "       'avg balance', 'monthly issuance', 'None', 'classic'],\n",
      "      dtype='object')\n",
      "Predictions:\n",
      "        Id  Predicted\n",
      "0    5895   0.137487\n",
      "1    7122   0.711660\n",
      "2    6173   0.205569\n",
      "3    6142   0.407271\n",
      "4    5358   0.338406\n",
      "..    ...        ...\n",
      "349  4989   0.269646\n",
      "350  5221   0.174417\n",
      "351  6402   0.295898\n",
      "352  5346   0.200271\n",
      "353  6748   0.195400\n",
      "\n",
      "[354 rows x 2 columns]\n",
      "Sucessfully stored the predictions in a file named 'testing_model.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "run_algorithm(algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.6708776595744681\n",
      "AUC=0.850354609929078\n",
      "AUC=0.7170212765957447\n",
      "Average AUC = 0.7460845153664302\n",
      "Best AUC = 0.850354609929078\n",
      "Predictions:\n",
      "        Id  Predicted\n",
      "0    5895   0.115853\n",
      "1    7122   0.716370\n",
      "2    6173   0.296558\n",
      "3    6142   0.370529\n",
      "4    5358   0.407886\n",
      "..    ...        ...\n",
      "349  4989   0.232598\n",
      "350  5221   0.195261\n",
      "351  6402   0.180590\n",
      "352  5346   0.277136\n",
      "353  6748   0.271324\n",
      "\n",
      "[354 rows x 2 columns]\n",
      "Sucessfully stored the predictions in a file named 'final.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_CV(algorithm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 7680 candidates, totalling 15360 fits\n",
      "Best Score:  0.5816373728029602\n",
      "Best Params:  {'classification__class_weight': None, 'classification__criterion': 'gini', 'classification__max_depth': 30, 'classification__max_features': 'log2', 'classification__min_impurity_decrease': 0.05, 'classification__min_samples_leaf': 6, 'classification__min_samples_split': 4, 'classification__splitter': 'best'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5816373728029602,\n",
       " {'classification__class_weight': None,\n",
       "  'classification__criterion': 'gini',\n",
       "  'classification__max_depth': 30,\n",
       "  'classification__max_features': 'log2',\n",
       "  'classification__min_impurity_decrease': 0.05,\n",
       "  'classification__min_samples_leaf': 6,\n",
       "  'classification__min_samples_split': 4,\n",
       "  'classification__splitter': 'best'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classification__criterion':['gini', 'entropy'],\n",
    "    'classification__splitter': [\"best\", \"random\"],\n",
    "    'classification__max_depth': [5, 10, 20, 30, 40],\n",
    "    'classification__min_samples_split': [2, 4, 6, 8],\n",
    "    'classification__min_samples_leaf': [1, 2, 4, 6],\n",
    "    'classification__max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'classification__min_impurity_decrease': [0.05, 0.1, 0.2, 0.3],\n",
    "    'classification__class_weight': [\"balanced\", None]\n",
    "}\n",
    "\n",
    "getBestSearch(\"DT\",param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n",
      "Best Score:  0.5121800801726797\n",
      "Best Params:  {'classification__max_depth': 110, 'classification__max_features': 2, 'classification__min_samples_leaf': 3, 'classification__min_samples_split': 8, 'classification__n_estimators': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5121800801726797,\n",
       " {'classification__max_depth': 110,\n",
       "  'classification__max_features': 2,\n",
       "  'classification__min_samples_leaf': 3,\n",
       "  'classification__min_samples_split': 8,\n",
       "  'classification__n_estimators': 300})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classification__max_depth': [80, 90, 100, 110],\n",
    "    'classification__max_features': [2, 3],\n",
    "    'classification__min_samples_leaf': [3, 4, 5],\n",
    "    'classification__min_samples_split': [8, 10, 12],\n",
    "    'classification__n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "getBestSearch(\"RF\",param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best Score:  0.37765957446808507\n",
      "Best Params:  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\outros\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.37765957446808507, {})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {}\n",
    " \n",
    "getBestSearch(\"LR\",param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 23040 candidates, totalling 46080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "9360 fits failed out of a total of 46080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 546, in _fit\n",
      "    self._tree = BallTree(\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 957, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 270, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 610, in sklearn.neighbors._dist_metrics.WMinkowskiDistance.__init__\n",
      "TypeError: __init__() takes exactly 2 positional arguments (1 given)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 546, in _fit\n",
      "    self._tree = BallTree(\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 957, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 270, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 455, in sklearn.neighbors._dist_metrics.SEuclideanDistance.__init__\n",
      "TypeError: __init__() takes exactly 1 positional argument (0 given)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 546, in _fit\n",
      "    self._tree = BallTree(\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 957, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 270, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 671, in sklearn.neighbors._dist_metrics.MahalanobisDistance.__init__\n",
      "ValueError: Must provide either V or VI for Mahalanobis distance\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 546, in _fit\n",
      "    self._tree = BallTree(\n",
      "  File \"sklearn\\neighbors\\_binary_tree.pxi\", line 966, in sklearn.neighbors._ball_tree.BinaryTree.__init__\n",
      "  File \"sklearn\\neighbors\\_dist_metrics.pyx\", line 1011, in sklearn.neighbors._dist_metrics.HaversineDistance._validate_data\n",
      "ValueError: Haversine distance only valid in 2 dimensions\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'wminkowski' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'seuclidean' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'mahalanobis' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'haversine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'hamming' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'canberra' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'braycurtis' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'infinity' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['brute']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 437, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 374, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'p' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['brute']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.5871877890841812\n",
      "Best Params:  {'classification__algorithm': 'kd_tree', 'classification__leaf_size': 80, 'classification__metric': 'infinity', 'classification__n_neighbors': 8, 'classification__p': 10, 'classification__weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tester\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.50516497 0.51742214 0.55928153 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5871877890841812,\n",
       " {'classification__algorithm': 'kd_tree',\n",
       "  'classification__leaf_size': 80,\n",
       "  'classification__metric': 'infinity',\n",
       "  'classification__n_neighbors': 8,\n",
       "  'classification__p': 10,\n",
       "  'classification__weights': 'uniform'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classification__n_neighbors': [2, 3, 4, 5, 8, 10],\n",
    "    'classification__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'classification__weights': ['uniform', 'distance'],\n",
    "    'classification__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis', 'haversine', 'hamming', 'canberra', 'braycurtis', 'cityblock', 'infinity', 'l1', 'l2', 'p'],\n",
    "    'classification__leaf_size': [10, 20, 30, 50, 80, 150],\n",
    "    'classification__p': [1, 2, 3, 5, 10]\n",
    "}\n",
    "\n",
    "getBestSearch(\"KNN\",param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(y_test,y_predicted):\n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_predicted,pos_label=-1)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.fill_between(fpr,tpr,color=\"lightskyblue\")\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'w--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1.01])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(n_clusters=3)\n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(\"../database/banking_data\")\n",
    "\n",
    "train = pd.read_sql_query(\"SELECT * FROM loan_united_train\", con)\n",
    "\n",
    "con.close()\n",
    "\n",
    "df = utils.normalize_category(train)\n",
    "# df = utils.normalization(df,'status')\n",
    "\n",
    "X = df.drop(columns=['status'])\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=3).fit(X)\n",
    "# labels = kmeans_model.labels_\n",
    "# metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "\n",
    "pprint(kmeans_model)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'loan_id', 'loan_amount', 'loan_duration', 'payments',\n",
       "       'status', 'no. of inhabitants',\n",
       "       'account_district no. of municipalities with inhabitants < 499',\n",
       "       'account_district no. of municipalities with inhabitants 500-1999',\n",
       "       'account_district no. of municipalities with inhabitants 2000-9999',\n",
       "       'account_district no. of municipalities with inhabitants >10000',\n",
       "       'account_district no. of cities',\n",
       "       'account_district ratio of urban inhabitants',\n",
       "       'account_district average salary',\n",
       "       'account_district unemploymant rate '95',\n",
       "       'account_district unemploymant rate '96',\n",
       "       'account_district unemploymant_growth',\n",
       "       'account_district no. of enterpreneurs per 1000 inhabitants',\n",
       "       'account_district no. of commited crimes '95',\n",
       "       'account_district no. of commited crimes '96',\n",
       "       'account_district crime_growth', 'account_district total_crime', 'code',\n",
       "       'client_district no. of inhabitants',\n",
       "       'client_district no. of municipalities with inhabitants < 499',\n",
       "       'client_district no. of municipalities with inhabitants 500-1999',\n",
       "       'client_district no. of municipalities with inhabitants 2000-9999',\n",
       "       'client_district no. of municipalities with inhabitants >10000',\n",
       "       'client_district no. of cities',\n",
       "       'client_district ratio of urban inhabitants',\n",
       "       'client_district average salary',\n",
       "       'client_district unemploymant rate '95',\n",
       "       'client_district unemploymant rate '96',\n",
       "       'client_district unemploymant_growth',\n",
       "       'client_district no. of enterpreneurs per 1000 inhabitants',\n",
       "       'client_district no. of commited crimes '95',\n",
       "       'client_district no. of commited crimes '96',\n",
       "       'client_district crime_growth', 'client_district total_crime',\n",
       "       'card_issued', 'no. movements', 'min no. trans', 'max no. trans',\n",
       "       'avg no. trans', 'min balance', 'max balance', 'avg balance',\n",
       "       'age_on_loan', 'issuance after transaction', 'monthly issuance',\n",
       "       'weekly issuance', 'female', 'male', 'None', 'classic', 'gold',\n",
       "       'junior'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df().columns"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5c685faadbcbae1551fd6d5683e133251e0ca8e77eadbbc8e83131f99b1b14"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
