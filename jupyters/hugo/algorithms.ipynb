{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c3bdb321085b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "### imported Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "### Imported Scripts\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data\n",
    "def split_dataset(df,ratio=0.7,debug=False):\n",
    "\n",
    "    ### Seperate the precition columns from output\n",
    "    X = df.drop(columns=['loan_success'])\n",
    "    y = df['loan_success']\n",
    "\n",
    "    ### Apply splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=ratio,test_size=1-ratio)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest(X_train,y_train):\n",
    "    return RandomForestClassifier(n_estimators=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(y_test,y_predicted):\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_predicted,pos_label=-1)    \n",
    "    return metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(debug = False,write=False):\n",
    "\n",
    "    print(\"Running Random Forest Algorithm\")\n",
    "    model = training_forest(debug)\n",
    "    testing_forest(model,debug=debug,write=write)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_forest(debug=False):\n",
    "    ### Getting the dataset\n",
    "    train = pd.read_csv('../../project/banking_data/loanUnitedTrain.csv', sep=',')\n",
    "    train = utils.normalize_category(train)\n",
    "\n",
    "    ### Getting a Model from training\n",
    "    X_train,X_test,y_train,y_test = split_dataset(train)\n",
    "\n",
    "    rf = get_random_forest(X_train,y_train)\n",
    "    model = rf.fit(X_train,y_train)\n",
    "\n",
    "    y_predicted = model.predict_proba(X_test)\n",
    "\n",
    "    y_final = y_predicted.transpose()[0]\n",
    "\n",
    "    if debug:\n",
    "        score = model.score(X_test,y_test)\n",
    "        auc = get_auc(y_test,y_final)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Auc: {auc}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_forest(model,debug=False,write=False):\n",
    "    test = pd.read_csv('../../project/banking_data/loanUnitedTest.csv', sep=',')\n",
    "    test = utils.normalize_category(test)\n",
    "\n",
    "    X = test.drop(columns=['loan_success'])\n",
    "\n",
    "    y_predicted = model.predict_proba(X)\n",
    "    y_final = y_predicted.transpose()[0]\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    final_df['Id'] = test[\"loan_id\"]\n",
    "    final_df['Predicted'] = y_final\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Predictions:\\n {final_df}\")\n",
    "    \n",
    "    if write:\n",
    "        final_df.to_csv('out.csv', index=False)\n",
    "        print(\"Sucessfully stored the predictions in a file named 'out.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Random Forest Algorithm\n",
      "Score: 0.8787878787878788\n",
      "Auc: 0.7491596638655463\n",
      "Predictions:\n",
      "        Id  Predicted\n",
      "0    5895   0.000000\n",
      "1    7122   0.733333\n",
      "2    6173   0.000000\n",
      "3    6142   0.066667\n",
      "4    5358   0.400000\n",
      "5    6095   0.000000\n",
      "6    6878   0.066667\n",
      "7    6554   0.333333\n",
      "8    6793   0.200000\n",
      "9    7286   0.000000\n",
      "10   6076   0.000000\n",
      "11   5134   0.066667\n",
      "12   5419   0.400000\n",
      "13   6255   0.266667\n",
      "14   5656   0.000000\n",
      "15   6934   0.333333\n",
      "16   6028   0.000000\n",
      "17   6490   0.066667\n",
      "18   6415   0.266667\n",
      "19   7087   0.000000\n",
      "20   5420   0.133333\n",
      "21   5977   0.066667\n",
      "22   6824   0.533333\n",
      "23   5207   0.333333\n",
      "24   7115   0.266667\n",
      "25   7250   0.000000\n",
      "26   6010   0.066667\n",
      "27   6088   0.066667\n",
      "28   5682   0.333333\n",
      "29   7201   0.266667\n",
      "..    ...        ...\n",
      "324  5698   0.000000\n",
      "325  5169   0.133333\n",
      "326  7294   0.066667\n",
      "327  5318   0.066667\n",
      "328  5368   0.066667\n",
      "329  6923   0.066667\n",
      "330  5463   0.000000\n",
      "331  5265   0.000000\n",
      "332  6321   0.133333\n",
      "333  5226   0.200000\n",
      "334  6868   0.000000\n",
      "335  4967   0.533333\n",
      "336  5293   0.000000\n",
      "337  5865   0.000000\n",
      "338  5841   0.000000\n",
      "339  5526   0.000000\n",
      "340  6852   0.066667\n",
      "341  6469   0.133333\n",
      "342  6168   0.066667\n",
      "343  7292   0.133333\n",
      "344  5036   0.066667\n",
      "345  5644   0.466667\n",
      "346  6856   0.266667\n",
      "347  5428   0.266667\n",
      "348  5027   0.000000\n",
      "349  4989   0.133333\n",
      "350  5221   0.000000\n",
      "351  6402   0.066667\n",
      "352  5346   0.200000\n",
      "353  6748   0.133333\n",
      "\n",
      "[354 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "run_random_forest(debug=True,write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uses a grid search to generate random parameters to find the best grid model\n",
    "def getBestSearch(algorithm,grid,debug=True):\n",
    "\n",
    "    train = pd.read_csv('../../project/banking_data/loanUnitedTrain.csv', sep=',')\n",
    "    train = utils.normalize_category(train)\n",
    "\n",
    "    X = train.drop(columns=['loan_success'])\n",
    "    y = train['loan_success']\n",
    "\n",
    "    alg = algorithm(X,y)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = alg, param_grid = grid, cv = 2, n_jobs = -1, verbose = 2)\n",
    "\n",
    "    model = grid_search.fit(X,y)\n",
    "\n",
    "    if debug:\n",
    "        print('Best Score: ', model.best_score_)\n",
    "        print('Best Params: ', model.best_params_)\n",
    "    \n",
    "    return model.best_score_, model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 576 candidates, totalling 1152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1152 out of 1152 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.875\n",
      "Best Params:  {'bootstrap': False, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.875,\n",
       " {'bootstrap': False,\n",
       "  'max_depth': 80,\n",
       "  'max_features': 3,\n",
       "  'min_samples_leaf': 3,\n",
       "  'min_samples_split': 10,\n",
       "  'n_estimators': 300})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "### Uncomment to run (WARNING: Takes like 5 minutes)\n",
    "# getBestSearch(get_random_forest,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_train, y_train)\n",
    "Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC())])\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sampling (This should work if the ASHDASJDSAKD LIBRARY IS IMPORTED)\n",
    "def build_pipeline(algorithm,oversample=True):\n",
    "\n",
    "\n",
    "    if(oversample):\n",
    "        return Pipeline(['classification',algorithm,\n",
    "                ('sampling',SMOTE(random_state = 20))\n",
    "        ])\n",
    "    else:\n",
    "        return  Pipeline(['classification',algorithm\n",
    "        ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.7298245614035088\n",
      "AUC=0.7134502923976608\n",
      "AUC=0.9047619047619049\n",
      "AUC=0.7956349206349207\n",
      "AUC=0.8313492063492063\n",
      "Average AUC = 0.7950041771094403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train = pd.read_csv('../../project/banking_data/loanUnitedTrain.csv', sep=',')\n",
    "df = utils.normalize_category(train)\n",
    "# df = utils.normalization(df,'loan_success')\n",
    "\n",
    "X = df.drop(columns=['loan_success'])\n",
    "y = df['loan_success']\n",
    "\n",
    "algorithm = RandomForestClassifier(bootstrap = False,\n",
    "                                    max_depth = 80,\n",
    "                                    max_features = 3,\n",
    "                                    min_samples_leaf = 3,\n",
    "                                    min_samples_split = 12,\n",
    "                                    n_estimators = 100)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=True, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "auc_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    ### Train the model\n",
    "    algorithm.fit(X_train, y_train)\n",
    "\n",
    "    ### Predict the outcome with the test data\n",
    "    y_pred = algorithm.predict_proba(X_test)\n",
    "    y_final = y_pred.transpose()[0]\n",
    "\n",
    "    auc = get_auc(y_test, y_final)\n",
    "    auc_list.append(auc)\n",
    "    print(f\"AUC={auc}\")\n",
    "\n",
    "### TODO: display statistics?\n",
    "avg = sum(auc_list)/len(auc_list)\n",
    "print(f\"Average AUC = {avg}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c5c685faadbcbae1551fd6d5683e133251e0ca8e77eadbbc8e83131f99b1b14"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
